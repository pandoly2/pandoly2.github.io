---
title: "퍼셉트론 (perceptron)"
date: 2022-04-20T00:00:00+00:00
author: pandoly2
layout: post
permalink: /perceptron/
categories: Genel
tags: [pandoly2, machine learning, AI]
use_math: true
---

### 퍼셉트론 아이디어
 - 지금까지 정리한 linear regression , logistic regression과 같은 개념으로 여러개의 입력데이터를 받아 하나의 출력을 갖는 구조를 퍼셉트론이라고 부름.
 - linear regression으로 최적의 구분선을 찾고 classification으로 데이터를 분류하는것이 개념적으로 동일해 보임.

### 퍼셉트론 탄생
 - 퍼셉트론은 프랑크 로젠블라트가 1957년에 고안한 알고리즘입니다. (신경망(딥러닝)의 기원이 되는 알고리즘)
 - 퍼셉트론의 구조를 배우는 것은 신경망과 딥러닝으로 나아가는데 중요한 아이디어를 배우는 일.

### 퍼셉트론이란?
![perceptron_basic_0](/assets/images/blog_images/Perceptron/perceptron_detail.png)
출처 : WikiDocs

 - 퍼셉트론은 다수의 신호를 입력으로 받아 하나의 신호를 출력 (신호 : 전류나 강물처럼 흐름이 있는 것)
 - 퍼셉트론의 신호는 '흐른다/안 흐른다(1이나 0)'의 두 가지 값을 가질수 있음.
 
![perceptron_basic](/assets/images/blog_images/Perceptron/perceptron.png)
출처 : NeoWizard

 - x1과 x2는 입력신호, y는 출력 신호, w1과 w2는 가중치를 의미
 - 원을 **뉴런** 또는 **노드**라고 부른다
 - 입력 신호가 뉴런에 보내질 때는 각각 고유한 가중치가 곱해진다.
 - 뉴런에서 전달 받은 신호의 총합이 임계값 θ를 넘을때만 1을 출력한다 (활성화 함수 or classification 함수)

 - 수식 : 
 $$
y\ =\ \begin{cases}0\ \left({w}_1{x}_1\ +\ {w}_2{x}_2\ \le \ \theta \right)\\1\ \left({w}_1x_1\ +\ {w}_2x_2\ >\ \theta \right)\end{cases}
 $$

 - 퍼셉트론은 복수의 입력 신호 각각에 가중치를 부여한다. 가중치는 각 신호가 결과에 주는 영향력을 조절하는 요소로 작용하며, 가중치가 클수록 해당 신호가 그만큼 더 중요함을 뜻한다.

### 퍼셉트론의 대표적인 예 단순논리회로 - AND, OR, NAD, XOR 문제
 - 우리는 다수의 입력에대하여 하나의 출력을 나타내는 단순한 논리회로를 퍼셉트론으로 나타낼수 있다. 
 (명칭은 퍼셉트론이라고 하지만 개념적으로는 적절한 선을 찾고(linear regression)그에 따른 분류를하는 것(classification))

#### AND Gate
![perceptron_and_gate](/assets/images/blog_images/Perceptron/perceptron_and.png)
출처 : NeoWizard

입력 x1, x2에대해 아래의의 수식에 대입해보면 만족하는 w1, w2, θ값을 여러개 찾을 수 있다.   
그중 하나의 예는 (0.5, 0.5, 0,7)   
 - 수식 : 
 $$
y\ =\ \begin{cases}0\ \left({w}_1{x}_1\ +\ {w}_2{x}_2\ \le \ \theta \right)\\1\ \left({w}_1x_1\ +\ {w}_2x_2\ >\ \theta \right)\end{cases}
 $$
   
- 이를 시각화하면 다음과 같은 그림이다. 

![perceptron_v_and](/assets/images/blog_images/Perceptron/perceptron_v_and.png)
출처 : WikiDocs


#### NAND Gate
![perceptron_nand_gate](/assets/images/blog_images/Perceptron/perceptron_nand.png)
출처 : NeoWizard

입력 x1, x2에대해 아래의의 수식에 대입해보면 만족하는 w1, w2, θ값을 여러개 찾을 수 있다.   
그중 하나의 예는 (-0.5, -0.5, -0,7)     

- 시각화   
![perceptron_v_nand](/assets/images/blog_images/Perceptron/perceptron_v_nand.png)
출처 : WikiDocs

#### OR Gate
![perceptron_or_gate](/assets/images/blog_images/Perceptron/perceptron_or.png)
출처 : NeoWizard

입력 x1, x2에대해 아래의의 수식에 대입해보면 만족하는 w1, w2, θ값을 여러개 찾을 수 있다.   
그중 하나의 예는 (0.5, 0.5, 0,2)  

- 시각화   
![perceptron_v_or](/assets/images/blog_images/Perceptron/perceptron_v_or.png)
출처 : WikiDocs

#### 가중치와 편향 수식
 - 위의 식에서 θ를 b(bias)로 변경하여 식을 나타내면 다음과같다. 
 즉, regression 에서도 확인했듯이 최적의 가중치와 바이어스를 찾는 문제와 같다.
 찾은 가중치와 바이어스에 의한 결과값이 0보다 큰지 작은지에 대한 분류 문제인것이다.

$$
y\ =\ \begin{cases}0\ \left({w}_1{x}_1\ +\ {w}_2{x}_2\ +\ b\le \ 0\right)\\1\ \left({w}_1x_1\ +\ {w}_2x_2\ \ +\ b>\ 0\right)\end{cases}    
$$

### 단일 퍼셉트론의 문제 - 논리회로 XOR

 - 다음은 XOR의 진리표이다.
 - 배타적 논리합이라는 논리 회로로 x1, x2 한쪽이 1일때만 1을 출력한다.

![perceptron_xor](/assets/images/blog_images/Perceptron/perceptron_xor.png)
출처 : NeoWizard

 - 시각화   
![perceptron_v_xor_0](/assets/images/blog_images/Perceptron/perceptron_v_xor_0.png)
출처 : NeoWizard

 - XOR은 위의 그림과같이 하나의 직선으로 두영역을 나눌수없다. 
 - 만약 직선 즉, 선형이라는 제약이 없다면 비선형으로 다음과 같이 나눌수 있을것이다. 

![perceptron_v_xor_1](/assets/images/blog_images/Perceptron/perceptron_v_xor_1.png)
출처 : NeoWizard

 - 하지만 비선형적 곡선을 나타내기어렵다. 
 - 우리는 여러개의 퍼셉트론을 엮어서 비선형처럼 만들수있다. (여러개의 직선)
 - 이 아이디어가 다층 퍼셉트론으로 단일 퍼셉트론의 한계를 극복했다.

![perceptron_v_xor_2](/assets/images/blog_images/Perceptron/perceptron_v_xor_2.png)
출처 : Wikidocs

#### XOR 문제의 솔루션

 - 단일 퍼셉트론 OR, NAND, AND를 결합하여 XOR을 만들었다. 
 - 입력 x1, x2를 각각(OR, NAND)의 gate에 입력으로 사용하고 그 출력을 다시 AND의 입력으로 사용한다.
 - 이렇게 함으로써 단일 직선으로 해결하기 어려웠던 문제를 해결 할 수 있다.

![perceptron_xor_solution](/assets/images/blog_images/Perceptron/perceptron_xor_solution.png)


#### XOR 논리게이트의 상세 Diagram
 - XOR의 논리게이트로 표현된 위의 그림을 우리가 학습했던 linear regression과 classification으로 표현하면 다음과 같다. 

![perceptron_xor_detail_solution](/assets/images/blog_images/Perceptron/perceptron_xor_detail_solution.png)

 










