---
title: "심층 신경망(딥러닝) 학습 관련 기술(optimization) - Batch Normalization"
date: 2022-05-03T00:00:00+00:00
author: pandoly2
layout: post
permalink: /optimization-parameter-3/
categories: Genel
tags: [pandoly2, machine learning, AI]
use_math: true
---

## 3. 배치 정규화
 - 학습을 시작하기전에 가중치의 분포, 특히 표준편차를 잘 잡아서 은닉층에 나타나는 데이터의 분포가 중앙에 쏠리거나 양 사이드에 나타나지않게 하므로써 학습이 잘되게 하는게 목표였다. 
 - affine층과 활성화 층 사이에 Batch Normalization층을 끼워 넣는다. 

 ![opt3_batch_normal_desc](/assets/images/blog_images/DeepNeuralNetwork3/ML.drawio.png)   
 - 데이터를 분산시키기위해 정규분포의 특성으로 만든다. (평균 0, 표준편차 1)
    1. 입력값이 다음과 같이 주어질때,    
    $$
        x\ =\ \begin{pmatrix}x_1\\x_2\\x_3\\...\\x_n\end{pmatrix}
    $$   
    2. 각 열에대한 평균, $$ \mu \ =\ \frac{1}{n}\sum _{i=1}^nx_i $$
    3. 각 열의 평균을 0으로 만듬 : $$ x_c\ =\ x\ -\ \mu $$
    4. x의 각 열의 분산 $$ \sigma ^2\ =\ \frac{1}{N}\sum _{i=1}^n\left(x_i\ -\ \mu \right)^2 $$
    5. 각 열을 normalize함, $$ x_n\ =\ \frac{x_c}{\sigma } $$ , (평균을 뺀 각열을 표준편차로 나눔)
    6. $$ x_n $$ 은 평균이 0, 표준 편차가 1인 분포를 따름.
    7. 여기에 데이터를 "잘"분산시키기위해 λ, β를 적용, $$ \lambda \ \cdot \ x_n\ +\ \beta  $$
    8. 결과값이 최종 y 값. (batch normalization 된 값)