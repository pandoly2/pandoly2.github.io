<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Pandoly2 - 생각나는대로</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2022-04-18T14:18:06+00:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>pandoly2</name>
   <email></email>
 </author>

 
 <entry>
   <title>경사하강법 (Gradient decent algorithm)</title>
   <link href="http://localhost:4000/gradient-decent/"/>
   <updated>2022-04-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/05-경사하강법</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>회귀와 손실함수 (Regression And loss-function)</title>
   <link href="http://localhost:4000/Regression-and-lossfunction/"/>
   <updated>2022-04-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/04-회귀와 손실함수</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;linear Regression&lt;/li&gt;
  &lt;li&gt;손실함수&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;회귀-regression&quot;&gt;회귀 (Regression)&lt;/h2&gt;
&lt;p&gt;※ 용어 :  회귀(Regression)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;원래 뜻은 예전으로 되돌아간다는 의미입니다. 영국의 유전학자 프랜시스 골턴이 부모와 자녀들 키의 연관 관계를 연구하다 보니, 개개인의 키는 결국 전체 키의 평균으로 수렴하는 경향이 있다는 걸 발견하고는 자신의 방법론에 ‘회귀 분석’이란 이름을 붙였다고 합니다.&lt;/li&gt;
  &lt;li&gt;‘회귀’라는 용어는 1885년 영국의 과학자 갈톤(F. Galton)이 발표한 ‘유전에 의하여 보통사람의 신장으로 회귀(Regression toward Meiocrity in Hereditary Stature’라는 논문에서 비롯되었다. 그는 아들의 키와 부모의 평균 키와의 관계를 분석하였는데, 부모의 키가 매우 클 때(또는 작을 때) 아들의 키는 일반적으로 평균키보다는 크지만(작지만) 그들의 부모만큼 크(작)지는 않다는 결론이다. 즉 부모의 키가 크(작)더라도 그 자식들은 결국 보통키로 회귀(돌아간다)한다는 뜻이다.
[출처] 회귀분석의 유래 : 대체 왜 Regression(회귀)이라고 불릴까?|작성자 바른인간&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;선형-회귀-linear-regression&quot;&gt;선형 회귀 (Linear Regression)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Trainig Data를 이용하여 데이터의 특성과 상관관계 등을 파악하고, 그 결과를 바탕으로 Training Data에 없는 미지의 데이터가 주어졌을 경우에, 그 결과를 연속적인 (숫자) 값으로 예측 하는것&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(예) 공부시간과 시험성적 관계, 집 평수와 집 가격 관계 등&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images/Regression/linearRegression_01.PNG&quot; alt=&quot;linearRegression_01&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
출처 : NeoWizard&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;학습 데이터는 입력(x)인 공부시간에 비례해서 출력(y)인 시험성적도 증가하는 경향이 있음
즉, 입력(x)과 출력(y)은 &lt;strong&gt;y = Wx + b&lt;/strong&gt; 형태로 나타낼 수 있음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images/Regression/linearRegression_02.PNG&quot; alt=&quot;linearRegression_01&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
출처 : NeoWizard&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;y = Wx + b&lt;/strong&gt;를 만족하는 다양한 &lt;strong&gt;1, 2, 3&lt;/strong&gt;과 같은 직선중, Training data의 특성을 가장 잘 표현할 수 있는 가중치 &lt;strong&gt;W(기울기)&lt;/strong&gt;, &lt;strong&gt;바이어스 b(y 절편 or 편차)&lt;/strong&gt;를 찾는 것이 학습(Learning) 개념임
※ 용어 정리 : 머신러닝에서는 W는 가중치(weight), b는 바이어스(bias) 라고 함.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;최적의-wweight와-bbias를-찾는방법&quot;&gt;최적의 W(weight)와 b(bias)를 찾는방법&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images/Regression/linearRegression_03.PNG&quot; alt=&quot;linearRegression_01&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
출처 : NeoWizard&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Training data의 정답(t)과 직선 y = Wx + b 값의 차이인 &lt;font color=&quot;red&quot;&gt; 오차(error) = t - y = t - (Wx + b)&lt;/font&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;오차가 크다면, 우리가 임의로 설정한 직선의 가중치와 바이어스 값이 잘못된 것이고, 오차가 작다면 직선의 가중치와 바이어스 값이 잘 된 것이기 때문에 미래 값 예측도 정확할 수 있다고 예상할 수 있음.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;즉, 머신러닝의 Regression 시스템은, &lt;strong&gt;모든 데이터&lt;/strong&gt;의 &lt;font color=&quot;red&quot;&gt; 오차(error) = t - y = t - (Wx + b)&lt;/font&gt;의 합이 최소가 되서, 미래 값을 잘 예측할 수 있는 가중치 W와 바이어스 b값을 찾아야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;손실함수-loss-function&quot;&gt;손실함수 (loss function)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;위의 &lt;strong&gt;최적의 W(weight)와 b(bias)를 찾는방법&lt;/strong&gt;에서 보았듯이 최적의 W(가중치)와 b(바이어스)를 찾는 것은 모든 데이터의 오차(error)가 작은 값을 찾으면된다.&lt;/li&gt;
  &lt;li&gt;즉, &lt;font color=&quot;red&quot;&gt;손실함수 (loss function)&lt;/font&gt;는, training data의 정답(t)과 입력(x)에 대한 계산 값 y의 차이(error)를 모두 더해 수식으로 나타낸 것.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images/Regression/linearRegression_03.PNG&quot; alt=&quot;linearRegression_01&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
출처 : NeoWizard&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;주의 : 각각의 오차를 모두 더해서 손실함수(loss function)을 구하면 각각의 오차가 (+), (-) 등이 동시에 존재하기 때문에 오차의 합이 0이 나올 수도 있음.&lt;/li&gt;
  &lt;li&gt;즉, 0 이라는 것이 최소 오차 값인지 아닌지를 판별하는 것이 어려움.&lt;/li&gt;
  &lt;li&gt;그래서, &lt;font color=&quot;red&quot;&gt;손실함수에서 오차(error)를 계산할 때는 양변에 제곱을 사용하여 계산함.&lt;/font&gt;&lt;/li&gt;
  &lt;li&gt;
\[{\left(t-y\right)}^2\ =\ {\left(t\ -\ {\left[Wx\ +\ b\right]}\right)}^2\]
  &lt;/li&gt;
  &lt;li&gt;즉, 오차는 언제나 양수이며, 제곱을 하기때문에 정답과 계산값 차이가 크다면, &lt;strong&gt;제곱에 의해 오차는 더 큰 값을 가지게 되어 머신러닝 학습에 있어 장점을 가짐&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;손실함수-식&quot;&gt;손실함수 식&lt;/h4&gt;

\[loss\ function= E(W,\ b) = \frac{\left({t}_1\ -\ y_1\right)^2\ +\left({t}_2\ -\ y_2\right)^2\ +\ \left({t}_3\ -\ y_3\right)^2\ +\ ...\ \ +\ \left({t}_n\ -\ y_n\right)^2\ \ }{n}\]

\[=\frac{\left[{t}_1\ -\ \left(Wx_1\ +\ b\right)\right]^2\ +\ \left[{t}_2\ -\ \left(Wx_2\ +\ b\right)\right]^2\ +\ ...\ +\ \left[{t}_n\ -\ \left(Wx_n\ +\ b\right)\right]^2\ \ }{n}\]

\[=\frac{1}{n}\sum _{i=1}^n\left[t_i\ -\ \left(Wx_i\ +\ b\right)\right]^2\]

&lt;ul&gt;
  &lt;li&gt;x 와 t 는 training data 에서 주어지는 값이므로, 손실함수(loss function)인 E(W, b)는 결국 W와 b에 영향을 받는 함수임.&lt;/li&gt;
  &lt;li&gt;E(W, b) 값이 작다는것은 정답(t, target)과 y = Wx + b에 의해 계산된 값의 평균 오차가 작다는 의미&lt;/li&gt;
  &lt;li&gt;평균 오차가 작다는 것은 임의의 데이터 x 가 주어질 경우, 확률적으로 미래의 결과값도 오차가 작을 것이라고 추측할 수 있음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;즉, training data를 바탕으로 손실 함수 E(W, b)가 최소값을 갖도록 (W, b)를 구하는 것이 (linear) regression의 최종 목적임.&lt;/strong&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>머신러닝 구분</title>
   <link href="http://localhost:4000/Which-is-the-MachineLearning/"/>
   <updated>2022-04-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/03-머신러닝구분</id>
   <content type="html">&lt;h2 id=&quot;구분&quot;&gt;구분&lt;/h2&gt;
&lt;p&gt;학습 방법에 따라 다음과 같이 나뉨&lt;/p&gt;

&lt;h3 id=&quot;지도학습-supervised&quot;&gt;지도학습 (Supervised)&lt;/h3&gt;
&lt;p&gt;: 입력 값(x)과 정답(t, label)을 포함하는 Training Data를 이용하여 학습하고, 그 학습된 결과를 바탕으로 미지의 데이터(Test Data)에 대해 미래 값을 예측(Predict)하는 방법 =&amp;gt; 대부분 머신러닝 문제는 지도학습에 해당됨.&lt;/p&gt;

&lt;p&gt;ex)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;시험공부 시간(입력)과 Pass/Fail(정답)을 이용하여 당락 여부 예측&lt;/li&gt;
  &lt;li&gt;집 평수(입력)와 가격 데이터(정답) 이요하여 임의의 평수 가격 예측&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;*지도학습은 학습결과를 바탕으로, 미래의 무엇을 예측하느냐에 따라 회귀, 분류등으로 구분할 수 있음&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;회귀-regression&quot;&gt;회귀 (Regression)&lt;/h4&gt;
&lt;p&gt;: Training Data를 이용하여 &lt;strong&gt;연속적인 (숫자) 값을 예측&lt;/strong&gt;하는 것을 말하며, 집평수와 가격 관계, 공부시간과 시험성적 등의 관계임.&lt;/p&gt;
&lt;h4 id=&quot;분류-classification&quot;&gt;분류 (Classification)&lt;/h4&gt;
&lt;p&gt;: Training Data를 이용하여 주어진 입력값이 &lt;strong&gt;어떤 종류&lt;/strong&gt;의 값인지 구별하는 것을 지칭함&lt;/p&gt;

&lt;h3 id=&quot;비지도학습-unsupervised&quot;&gt;비지도학습 (Unsupervised)&lt;/h3&gt;
&lt;p&gt;: Training Data에 정답은 없고 입력 데이터만 있기 때문에, 입력에 대한 정답을 찾는 것이 아닌 입력데이터의 패턴, 특성 등을 학습을 통해 발견하는 방법을 말함. &lt;br /&gt;
ex)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;군집화(Clustering) 알고리즘을 이용한 뉴스 그룹핑, 백화점의 상품 추천시스템 등&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;군집화-clustering&quot;&gt;군집화 (Clustering)&lt;/h4&gt;

</content>
 </entry>
 
 <entry>
   <title>수학개념 (Prerequisite for Machine Learning)</title>
   <link href="http://localhost:4000/Prerequisite-of-Math/"/>
   <updated>2022-04-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/02-수학개념(PreRequisiteForMachineLearning)</id>
   <content type="html">&lt;h2 id=&quot;수치미분&quot;&gt;수치미분&lt;/h2&gt;

&lt;h3 id=&quot;미분으로-얻을-수-있는-insight&quot;&gt;미분으로 얻을 수 있는 Insight&lt;/h3&gt;
&lt;p&gt;-&amp;gt; 입력 변수 x가 미세하게 변할때, 함수 f(x)가 얼마나 변하는지 알 수 있는 식을 구해라. &lt;br /&gt;
 -&amp;gt; 한수 f(x)는 입력 x의 미세한 변화에 얼마나 민감하게 반응하는지 알 수 있는 식을 구해라.      &lt;br /&gt;
&lt;strong&gt;Insight&lt;/strong&gt; &lt;br /&gt;
 -&amp;gt; 입력 x 를 현재 값에서 아주 조금 변화시키면, 함수 f(x)는 얼마나 변하는가? &lt;br /&gt;
 -&amp;gt; 함수 f(x)는 입력 x의 미세한 변화에 얼마나 민감하게 반응하는가?&lt;/p&gt;

&lt;font color=&quot;red&quot;&gt; 어떤 값 x가 아주조금 변할때 y값의 미세한 변화량을 나타내는 기울기 혹은 크기 &lt;/font&gt;

&lt;h3 id=&quot;기본-미분-공식&quot;&gt;기본 미분 공식&lt;/h3&gt;
&lt;p&gt;\(f&apos;\left(x\right)\ =\ \frac{df\left(x\right)}{dx}\ =\lim _{\Delta x \to 0}{\frac{f\left(\left(x\ +\ \Delta x\right)\ -\ f\left(x\right)\right)}{\Delta x}}\)&lt;/p&gt;

&lt;h3 id=&quot;중앙차미분&quot;&gt;중앙차미분&lt;/h3&gt;
&lt;p&gt;\(f&apos;\left(x\right)\ =\ \frac{df\left(x\right)}{dx}\ =\lim _{\Delta x\to 0}^{ }\frac{f\left(\left(x\ +\ \Delta x\right)\ -\ f\left(x\ -\ \Delta x\right)\right)}{2\Delta x}\)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images/NumericalDifferentiation/Numerical_Differentiation.jpg&quot; alt=&quot;Numerical_Differentiation&quot; title=&quot;Numerical Differentiation&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;참조 : &lt;a href=&quot;https://blog.naver.com/PostView.naver?blogId=mykepzzang&amp;amp;logNo=220072089756&amp;amp;parentCategoryNo=&amp;amp;categoryNo=16&amp;amp;viewDate=&amp;amp;isShowPopularPosts=false&amp;amp;from=postView&quot;&gt;https://blog.naver.com/PostView.naver?blogId=mykepzzang&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;편미분&quot;&gt;편미분&lt;/h3&gt;

&lt;p&gt;예 ) \(f\left(x,\ y\right)\ =\ 2x\ +\ 3xy\ +\ y3\) 에 대해,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;변수 x에 대하여 편미분 &lt;br /&gt;
\(\frac{\partial f\left(x,y\right)}{\partial x}\ =\ \frac{\partial \left(2x\ +\ 3xy\ +{y}^3\right)}{\partial x}\ =\ 2\ +\ 3y\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;변수 y에 대하여 편미분 &lt;br /&gt;
\(\frac{\partial f\left(x,y\right)}{\partial x}\ =\ \frac{\partial \left(2x\ +\ 3xy\ +{y}^3\right)}{\partial x}\ =\ 3x\ +\ 3y^2\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;chain-rule&quot;&gt;Chain Rule&lt;/h3&gt;
&lt;p&gt;합성함수란 여러 함수로 구성된 함수로서, 이러한 합성함수를 미분하려면 ‘합성함수를 구성하는 각 함수의 미분의 곱’으로 나타내는 chain rule(연쇄 법칙) 이용
Ref. NeoWizard PPT 5 page (개인용)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>4차 산업혁명의 키워드 인공지능</title>
   <link href="http://localhost:4000/what-is-the-machinlearning/"/>
   <updated>2022-04-18T00:00:00+00:00</updated>
   <id>http://localhost:4000/01-인공지능이란</id>
   <content type="html">&lt;h2 id=&quot;4차-산업-혁명&quot;&gt;4차 산업 혁명&lt;/h2&gt;
&lt;p&gt;2016년 스위스 다보스에서 개최된 세계경제 포럼에서 처음 언급됨&lt;/p&gt;

&lt;p&gt;학자에 따라 정의는 조금씩 다르지만, 대체로 &lt;strong&gt;4차 산업혁명&lt;/strong&gt;은 모든 것이 &lt;font color=&quot;red&quot;&gt;연결(Connectivity)&lt;/font&gt;되어 있는 환경에서 &lt;font color=&quot;red&quot;&gt;인공지능(Artificial Intelligence)&lt;/font&gt;에 의해 더운 편리하고 지능적인 사회로의 혁신적 변화를 지칭함.&lt;/p&gt;

&lt;h2 id=&quot;인공지능artificial-intelligence란&quot;&gt;인공지능(Artificial Intelligence)란&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images//WhatIstheAI/WhatIsthe_AI.drawio.png&quot; alt=&quot;WhatIsTheAI&quot; title=&quot;What is the AI&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;regression-classification&quot;&gt;Regression, Classification&lt;/h2&gt;
&lt;p&gt;Classification : 분류 &lt;br /&gt;
Regression : 회귀&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images//WhatIstheAI/Regression_Classification.png&quot; alt=&quot;WhatIsTheAI&quot; title=&quot;Regression &amp;amp; Classification&quot; width=&quot;100%&quot; height=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;딥러닝&quot;&gt;딥러닝&lt;/h2&gt;
&lt;p&gt;뉴런 - 상호작용  (퍼셉트론 설명)&lt;/p&gt;

&lt;h2 id=&quot;학습을-위한-전제조건prerequisite&quot;&gt;학습을 위한 전제조건(Prerequisite)&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;프로그래밍 개념&lt;/li&gt;
  &lt;li&gt;기본 수학 개념&lt;/li&gt;
  &lt;li&gt;행렬(Matrix) 연산&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>First post (글)</title>
   <link href="http://localhost:4000/first-post-content/"/>
   <updated>2022-04-16T00:00:00+00:00</updated>
   <id>http://localhost:4000/first-post-content</id>
   <content type="html">&lt;p&gt;Github page로 만들어본 블로그&lt;/p&gt;

&lt;p&gt;오늘은 무슨 기능이있는지 알아보자.&lt;/p&gt;

&lt;p&gt;*기본적으로 markdown kramdown을 사용하여 그린다.&lt;/p&gt;

&lt;p&gt;Python&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Python syntax highlighting&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;C언어&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hello world&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;JAVA&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HelloWorld&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello, World!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; 
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h1 id=&quot;샾-강조-1&quot;&gt;샾 강조 1&lt;/h1&gt;
&lt;h2 id=&quot;샾샾-강조-2&quot;&gt;샾샾 강조 2&lt;/h2&gt;
&lt;h3 id=&quot;샾샾샾-강조-3&quot;&gt;샾샾샾 강조 3&lt;/h3&gt;
&lt;h4 id=&quot;샾샾샾샾-강조-4&quot;&gt;샾샾샾샾 강조 4&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://pandoly2.github.io&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;나는 &lt;strong&gt;Pandoly2&lt;/strong&gt; 입니다.
나는 &lt;em&gt;Pandoly2&lt;/em&gt; 입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/blog_images/panda.jpg&quot; alt=&quot;Panda Image&quot; title=&quot;Panda&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;항목 1&lt;/li&gt;
  &lt;li&gt;항목 2&lt;/li&gt;
  &lt;li&gt;항목 3&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;첫번째&lt;/li&gt;
  &lt;li&gt;두번째&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;참조 : &lt;a href=&quot;https://sukwonyun.github.io/jekyll/Jekyll-%ED%85%8C%EB%A7%88%EC%97%90%EC%84%9C-Latex-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/&quot;&gt;마크다운 수식 넣는 법 링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;끝.&lt;/p&gt;
</content>
 </entry>
 

</feed>
